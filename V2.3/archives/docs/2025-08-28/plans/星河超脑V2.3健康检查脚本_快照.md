#!/bin/bash
# æ˜Ÿæ²³è¶…è„‘V2.3æ—¥å¸¸å¥åº·æ£€æŸ¥è„šæœ¬

echo "=== æ˜Ÿæ²³è¶…è„‘V2.3å¥åº·æ£€æŸ¥å¼€å§‹ ==="

# 1. æ ¸å¿ƒæœåŠ¡çŠ¶æ€æ£€æŸ¥
echo "æ£€æŸ¥æ ¸å¿ƒæœåŠ¡çŠ¶æ€..."
services=("brain-core" "memory-engine" "emotion-simulator" "multi-agent-coordinator")
for service in "${services[@]}"; do
    if systemctl is-active --quiet $service; then
        echo "âœ… $service æœåŠ¡æ­£å¸¸è¿è¡Œ"
    else
        echo "âŒ $service æœåŠ¡å¼‚å¸¸ï¼Œéœ€è¦ç«‹å³å…³æ³¨"
        exit 1
    fi
done

# 2. æ€§èƒ½æŒ‡æ ‡æ£€æŸ¥
echo "æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡..."
response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080/health)
if (( $(echo "$response_time < 0.2" | bc -l) )); then
    echo "âœ… å“åº”æ—¶é—´æ­£å¸¸: ${response_time}s"
else
    echo "âš ï¸ å“åº”æ—¶é—´å¼‚å¸¸: ${response_time}s"
fi

# 3. èµ„æºä½¿ç”¨æ£€æŸ¥
echo "æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ..."
memory_usage=$(free | grep Mem | awk '{printf "%.2f", $3/$2 * 100.0}')
cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')

if (( $(echo "$memory_usage < 80" | bc -l) )); then
    echo "âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸: ${memory_usage}%"
else
    echo "âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜: ${memory_usage}%"
fi

# 4. æ—¥å¿—é”™è¯¯æ£€æŸ¥
echo "æ£€æŸ¥æœ€è¿‘1å°æ—¶çš„é”™è¯¯æ—¥å¿—..."
error_count=$(journalctl -u brain-core --since "1 hour ago" | grep -c "ERROR")
if [ $error_count -lt 5 ]; then
    echo "âœ… é”™è¯¯æ—¥å¿—æ•°é‡æ­£å¸¸: $error_count æ¡"
else
    echo "âš ï¸ é”™è¯¯æ—¥å¿—è¿‡å¤š: $error_count æ¡ï¼Œéœ€è¦æ£€æŸ¥"
fi

echo "=== å¥åº·æ£€æŸ¥å®Œæˆ ==="
```

#### æ€§èƒ½è°ƒä¼˜SOP
```python
class PerformanceTuner:
    async def auto_tune_system(self):
        """è‡ªåŠ¨æ€§èƒ½è°ƒä¼˜æµç¨‹"""
        
        print("ğŸ”§ å¼€å§‹è‡ªåŠ¨æ€§èƒ½è°ƒä¼˜...")
        
        # 1. åˆ†æå½“å‰æ€§èƒ½ç“¶é¢ˆ
        bottlenecks = await self.analyze_bottlenecks()
        print(f"å‘ç°æ€§èƒ½ç“¶é¢ˆ: {bottlenecks}")
        
        # 2. åŠ¨æ€è°ƒæ•´å‚æ•°
        optimizations = []
        
        if "memory" in bottlenecks:
            await self.optimize_memory_usage()
            optimizations.append("å†…å­˜ä¼˜åŒ–")
            
        if "cpu" in bottlenecks:
            await self.optimize_cpu_usage()
            optimizations.append("CPUä¼˜åŒ–")
            
        if "io" in bottlenecks:
            await self.optimize_io_performance()
            optimizations.append("I/Oä¼˜åŒ–")
            
        # 3. éªŒè¯ä¼˜åŒ–æ•ˆæœ
        await asyncio.sleep(300)  # ç­‰å¾…5åˆ†é’Ÿè§‚å¯Ÿæ•ˆæœ
        after_metrics = await self.collect_performance_metrics()
        
        improvement = self.calculate_improvement(after_metrics)
        
        print(f"âœ… æ€§èƒ½è°ƒä¼˜å®Œæˆ:")
        print(f"   åº”ç”¨ä¼˜åŒ–: {', '.join(optimizations)}")
        print(f"   æ€§èƒ½æå‡: {improvement:.1%}")
        
        return {
            "optimizations": optimizations,
            "improvement": improvement,
            "timestamp": datetime.utcnow()
        }
```

### C.2 åº”æ€¥å“åº”é¢„æ¡ˆ

#### P0çº§æ•…éšœåº”æ€¥é¢„æ¡ˆ
```yaml
emergency_response_p0:
  trigger_conditions:
    - "ç³»ç»Ÿå®Œå…¨ä¸å¯ç”¨"
    - "æ•°æ®ä¸¢å¤±é£é™©"
    - "å®‰å…¨æ¼æ´è¢«åˆ©ç”¨"
    
  immediate_actions:
    - action: "æ¿€æ´»åº”æ€¥å“åº”å°ç»„"
      owner: "å€¼ç­å·¥ç¨‹å¸ˆ"
      timeout: "5åˆ†é’Ÿ"
      
    - action: "æ‰§è¡Œè‡ªåŠ¨æ•…éšœéš”ç¦»"
      owner: "ç›‘æ§ç³»ç»Ÿ"
      timeout: "2åˆ†é’Ÿ"
      
    - action: "å¯åŠ¨å¤‡ç”¨ç³»ç»Ÿ"
      owner: "åŸºç¡€è®¾æ–½å›¢é˜Ÿ"
      timeout: "10åˆ†é’Ÿ"
      
  communication_plan:
    internal:
      - "æŠ€æœ¯å›¢é˜Ÿç¾¤ç»„ (ç«‹å³)"
      - "ç®¡ç†å±‚é€šæŠ¥ (15åˆ†é’Ÿå†…)"
      - "å®¢æˆ·æœåŠ¡å›¢é˜Ÿ (30åˆ†é’Ÿå†…)"
      
    external:
      - "çŠ¶æ€é¡µæ›´æ–° (10åˆ†é’Ÿå†…)"
      - "å…³é”®å®¢æˆ·é€šçŸ¥ (30åˆ†é’Ÿå†…)"
      - "å…¬å¼€å£°æ˜ (å¦‚éœ€è¦ï¼Œ1å°æ—¶å†…)"
      
  recovery_steps:
    1. "é—®é¢˜å®šä½ä¸æ ¹å› åˆ†æ"
    2. "åˆ¶å®šä¿®å¤æ–¹æ¡ˆ"
    3. "åœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯ä¿®å¤"
    4. "ç”Ÿäº§ç¯å¢ƒæ¸è¿›å¼ä¿®å¤"
    5. "æœåŠ¡æ¢å¤éªŒè¯"
    6. "äº‹åæ€»ç»“ä¸æ”¹è¿›"
```

#### è‡ªåŠ¨å›æ»šæœºåˆ¶
```python
class AutoRollback:
    async def monitor_and_rollback(self, deployment_id: str):
        """è‡ªåŠ¨å›æ»šç›‘æ§æœºåˆ¶"""
        
        print(f"ğŸ” å¼€å§‹ç›‘æ§éƒ¨ç½² {deployment_id}")
        
        # ç›‘æ§å…³é”®æŒ‡æ ‡
        monitoring_duration = 1800  # 30åˆ†é’Ÿ
        check_interval = 60  # æ¯åˆ†é’Ÿæ£€æŸ¥
        
        start_time = time.time()
        rollback_triggered = False
        
        while time.time() - start_time < monitoring_duration:
            try:
                # æ£€æŸ¥å¥åº·æŒ‡æ ‡
                health_score = await self.calculate_health_score()
                
                # å›æ»šè§¦å‘æ¡ä»¶
                if health_score < 0.7:  # å¥åº·åˆ†æ•°ä½äº70%
                    print(f"âš ï¸ å¥åº·åˆ†æ•°è¿‡ä½: {health_score:.2%}")
                    await self.trigger_rollback(deployment_id)
                    rollback_triggered = True
                    break
                    
                # æ£€æŸ¥é”™è¯¯ç‡
                error_rate = await self.get_error_rate()
                if error_rate > 0.05:  # é”™è¯¯ç‡è¶…è¿‡5%
                    print(f"âš ï¸ é”™è¯¯ç‡è¿‡é«˜: {error_rate:.2%}")
                    await self.trigger_rollback(deployment_id)
                    rollback_triggered = True
                    break
                    
                print(f"âœ… å¥åº·æ£€æŸ¥é€šè¿‡ - åˆ†æ•°: {health_score:.2%}, é”™è¯¯ç‡: {error_rate:.2%}")
                await asyncio.sleep(check_interval)
                
            except Exception as e:
                print(f"âŒ ç›‘æ§å¼‚å¸¸: {e}")
                # ç›‘æ§å¼‚å¸¸ä¹Ÿè§¦å‘å›æ»š
                await self.trigger_rollback(deployment_id)
                rollback_triggered = True
                break
        
        if not rollback_triggered:
            print("âœ… éƒ¨ç½²ç›‘æ§æœŸç»“æŸï¼Œç³»ç»Ÿè¿è¡Œç¨³å®š")
            await self.mark_deployment_stable(deployment_id)
        
    async def trigger_rollback(self, deployment_id: str):
        """æ‰§è¡Œè‡ªåŠ¨å›æ»š"""
        print(f"ğŸ”„ è§¦å‘è‡ªåŠ¨å›æ»š: {deployment_id}")
        
        # 1. åœæ­¢å½“å‰éƒ¨ç½²æµé‡
        await self.stop_traffic_to_new_version()
        
        # 2. æ¢å¤åˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬
        previous_version = await self.get_previous_stable_version()
        await self.restore_version(previous_version)
        
        # 3. éªŒè¯å›æ»šæˆåŠŸ
        rollback_success = await self.verify_rollback_success()
        
        if rollback_success:
            print("âœ… è‡ªåŠ¨å›æ»šæˆåŠŸ")
            # å‘é€å›æ»šæˆåŠŸé€šçŸ¥
            await self.send_rollback_notification(deployment_id, "SUCCESS")
        else:
            print("âŒ è‡ªåŠ¨å›æ»šå¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥")
            await self.escalate_to_human(deployment_id)
```

---

## é™„å½•A: æœ¯è¯­è¡¨ä¸ç¼©å†™

### æ ¸å¿ƒæŠ€æœ¯æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ç¼©å†™ | å®Œæ•´å®šä¹‰ | é€‚ç”¨èŒƒå›´ |
|------|----------|----------|----------|
| æ˜Ÿæ²³è¶…è„‘ | StarRiver Brain| å…·å¤‡è‡ªä¸»è¿›åŒ–èƒ½åŠ›çš„å¤šæ¨¡æ€AIç³»ç»Ÿ | æ•´ä½“ç³»ç»Ÿ |
| å¿ƒæ™ºæ¶æ„ | Mental Architecture | AIç³»ç»Ÿçš„è®¤çŸ¥å¤„ç†æ¡†æ¶å’Œæ¨ç†ç»“æ„ | ç¬¬6ç«  |
| è®°å¿†æ³›åŒ– | Memory Generalization | è·¨åŸŸçŸ¥è¯†è¿ç§»å’ŒæŠ½è±¡èƒ½åŠ› | ç¬¬7ç«  |
| å¤šæ™ºèƒ½ä½“åä½œ | Multi-Agent Collaboration | åˆ†å¸ƒå¼AIå®ä½“ååŒå·¥ä½œæœºåˆ¶ | ç¬¬8ç«  |
| æƒ…æ„Ÿä»¿çœŸ | Emotion Simulation | æ¨¡æ‹Ÿäººç±»æƒ…æ„ŸçŠ¶æ€çš„è®¡ç®—æ¨¡å‹ | ç¬¬9ç«  |
| ä¼¦ç†æ¨ç† | Ethical Reasoning | åŸºäºä»·å€¼è§‚çš„é“å¾·åˆ¤æ–­èƒ½åŠ› | æ¨ªå‘èƒ½åŠ› |

### è´¨é‡ä¿è¯æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ç¼©å†™ | å®Œæ•´å®šä¹‰ | é—¨ç¦é˜ˆå€¼ |
|------|----------|----------|----------|
| æœåŠ¡ç­‰çº§ç›®æ ‡ | SLO | Service Level Objective | P95 < 200ms |
| æœåŠ¡ç­‰çº§åè®® | SLA | Service Level Agreement | 99.9% å¯ç”¨æ€§ |
| é”™è¯¯é¢„ç®— | Error Budget | å…è®¸çš„æœåŠ¡é™çº§æ—¶é—´é…é¢ | 0.1% |
| å¹³å‡ä¿®å¤æ—¶é—´ | MTTR | Mean Time To Recovery | < 30åˆ†é’Ÿ |
| ä»£ç è¦†ç›–ç‡ | Code Coverage | æµ‹è¯•è¦†ç›–çš„ä»£ç æ¯”ä¾‹ | â‰¥ 85% |
| æŠ€æœ¯å€ºåŠ¡ | Technical Debt | å¿«é€Ÿå¼€å‘ç§¯ç´¯çš„ä»£ç è´¨é‡é—®é¢˜ | < 3å¤© |

### å‘å¸ƒç®¡ç†æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ç¼©å†™ | å®Œæ•´å®šä¹‰ | æ‰§è¡Œè´£ä»»æ–¹ |
|------|----------|----------|-----------|
| è“ç»¿éƒ¨ç½² | Blue-Green | ä¸¤å¥—ç¯å¢ƒåˆ‡æ¢çš„é›¶åœæœºéƒ¨ç½²æ–¹å¼ | DevOpså›¢é˜Ÿ |
| é‡‘ä¸é›€å‘å¸ƒ | Canary Release | æ¸è¿›å¼æµé‡åˆ‡æ¢çš„å‘å¸ƒç­–ç•¥ | å‘å¸ƒå·¥ç¨‹å¸ˆ |
| ç‰¹æ€§å¼€å…³ | Feature Toggle | è¿è¡Œæ—¶æ§åˆ¶åŠŸèƒ½å¯ç”¨çš„å¼€å…³æœºåˆ¶ | äº§å“å›¢é˜Ÿ |
| å›æ»šæ¼”ç»ƒ | Rollback Drill | å®šæœŸçš„æ•…éšœæ¢å¤èƒ½åŠ›éªŒè¯ | è¿ç»´å›¢é˜Ÿ |
| å˜æ›´å’¨è¯¢å§”å‘˜ä¼š | CAB | Change Advisory Board | æŠ€æœ¯å§”å‘˜ä¼š |

---

## é™„å½•B: é…ç½®æ¨¡æ¿ä¸æ£€æŸ¥æ¸…å•

### B.1 ç¯å¢ƒé…ç½®æ¨¡æ¿

```yaml
# V2.3ç¯å¢ƒé…ç½®æ¨¡æ¿
starriver_v23_config:
  system:
    version: "2.3.0"
    environment: "${ENV_TYPE}"  # dev/staging/prod
    debug_mode: false
    
  brain_core:
    mental_architecture:
      reasoning_depth: 7
      parallel_thoughts: 4
      consciousness_threshold: 0.85
      
    memory_system:
      long_term_capacity: "1TB"
      working_memory_slots: 16
      generalization_alpha: 0.3
      
    emotion_engine:
      empathy_coefficient: 0.7
      emotion_persistence: 300  # seconds
      facial_expression_sync: true
      
  multi_agent:
    coordination_protocol: "consensus_v2"
    agent_pool_size: 8
    collaboration_timeout: 30
    
  quality_gates:
    performance:
      response_time_p95_ms: 200
      throughput_qps: 1000
      memory_growth_limit: 0.2
      
    reliability:
      availability_sla: 0.999
      error_rate_threshold: 0.001
      recovery_time_minutes: 30
      
    security:
      input_sanitization: true
      rate_limiting_enabled: true
      audit_logging: true
      
  monitoring:
    metrics_retention_days: 90
    alerting_channels: ["slack", "email", "sms"]
    dashboard_refresh_seconds: 30
```

### B.2 å‘å¸ƒå‰æ£€æŸ¥æ¸…å•

#### åŠŸèƒ½éªŒæ”¶æ¸…å•
- [ ] **å¿ƒæ™ºæ¶æ„æ¨¡å—**
  - [ ] æ·±åº¦æ¨ç†èƒ½åŠ›æµ‹è¯•é€šè¿‡ (â‰¥7å±‚æ¨ç†)
  - [ ] å¹¶è¡Œæ€ç»´çº¿ç¨‹ç¨³å®šè¿è¡Œ (4çº¿ç¨‹)
  - [ ] æ„è¯†é˜ˆå€¼æ ¡å‡†å®Œæˆ (0.85)
  - [ ] ä¼¦ç†åˆ¤æ–­ä¸€è‡´æ€§éªŒè¯é€šè¿‡

- [ ] **è®°å¿†æ³›åŒ–æ¨¡å—**  
  - [ ] é•¿æœŸè®°å¿†å­˜å‚¨å®¹é‡è¾¾æ ‡ (1TB)
  - [ ] å·¥ä½œè®°å¿†æ§½ä½æ­£å¸¸ (16æ§½ä½)
  - [ ] è·¨åŸŸçŸ¥è¯†è¿ç§»æµ‹è¯•é€šè¿‡
  - [ ] æ³›åŒ–ç³»æ•°è°ƒä¼˜å®Œæˆ (Î±=0.3)

- [ ] **å¤šæ™ºèƒ½ä½“åä½œæ¨¡å—**
  - [ ] åè°ƒåè®®ç‰ˆæœ¬éªŒè¯ (consensus_v2)
  - [ ] æ™ºèƒ½ä½“æ± è§„æ¨¡é…ç½® (8ä¸ªagent)
  - [ ] åä½œè¶…æ—¶æœºåˆ¶æµ‹è¯• (30ç§’)
  - [ ] åˆ†å¸ƒå¼ä¸€è‡´æ€§éªŒè¯é€šè¿‡

- [ ] **æƒ…æ„Ÿä»¿çœŸæ¨¡å—**
  - [ ] å…±æƒ…ç³»æ•°æ ¡å‡† (0.7)
  - [ ] æƒ…æ„ŸæŒä¹…æ€§æœºåˆ¶ (300ç§’)
  - [ ] é¢éƒ¨è¡¨æƒ…åŒæ­¥åŠŸèƒ½
  - [ ] æƒ…æ„ŸçŠ¶æ€è½¬æ¢å›¾éªŒè¯

#### æ€§èƒ½éªŒæ”¶æ¸…å•
- [ ] **å“åº”æ€§èƒ½**
  - [ ] P95å“åº”æ—¶é—´ < 200ms
  - [ ] å¹³å‡å“åº”æ—¶é—´ < 100ms  
  - [ ] ååé‡ â‰¥ 1000 QPS
  - [ ] å¹¶å‘å¤„ç†èƒ½åŠ› â‰¥ 500 è¿æ¥

- [ ] **èµ„æºæ•ˆç‡**
  - [ ] å†…å­˜å¢é•¿ç‡ < 20%
  - [ ] CPUä½¿ç”¨ç‡å³°å€¼ < 80%
  - [ ] ç£ç›˜I/Oå»¶è¿Ÿ < 10ms
  - [ ] ç½‘ç»œå¸¦å®½åˆ©ç”¨ç‡ < 70%

#### å®‰å…¨éªŒæ”¶æ¸…å•
- [ ] **è¾“å…¥å®‰å…¨**
  - [ ] XSSæ”»å‡»é˜²æŠ¤éªŒè¯
  - [ ] SQLæ³¨å…¥é˜²æŠ¤æµ‹è¯•
  - [ ] æ¨¡æ¿æ³¨å…¥é˜²æŠ¤æ£€æŸ¥
  - [ ] è·¯å¾„éå†æ”»å‡»é˜²æŠ¤

- [ ] **æ•°æ®ä¿æŠ¤**
  - [ ] æ•æ„Ÿæ•°æ®è„±æ•æœºåˆ¶
  - [ ] ä¸ªäººä¿¡æ¯åŠ å¯†å­˜å‚¨
  - [ ] è®¿é—®æ—¥å¿—å®¡è®¡å®Œæ•´
  - [ ] æ•°æ®å¤‡ä»½æ¢å¤éªŒè¯

### B.3 Go/No-Goå†³ç­–çŸ©é˜µ

| å†³ç­–ç»´åº¦ | æƒé‡ | Goæ¡ä»¶ | No-Goæ¡ä»¶ | å½“å‰çŠ¶æ€ |
|----------|------|--------|-----------|----------|
| åŠŸèƒ½å®Œæ•´æ€§ | 30% | æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ | ä»»ä¸€æ ¸å¿ƒåŠŸèƒ½å¤±è´¥ | âœ… |
| æ€§èƒ½æŒ‡æ ‡ | 25% | SLOå…¨éƒ¨è¾¾æ ‡ | ä»»ä¸€SLOæœªè¾¾æ ‡ | âœ… |
| å®‰å…¨åˆè§„ | 20% | å®‰å…¨æ‰«æé›¶é«˜å±æ¼æ´ | å‘ç°é«˜å±å®‰å…¨æ¼æ´ | âœ… |
| ç¨³å®šæ€§ | 15% | 7å¤©æ— P0/P1æ•…éšœ | å­˜åœ¨æœªä¿®å¤P0æ•…éšœ | âš ï¸ |
| å›¢é˜Ÿå°±ç»ª | 10% | è¿ç»´å›¢é˜ŸåŸ¹è®­å®Œæˆ | å…³é”®äººå‘˜ä¸å¯ç”¨ | âœ… |

**å†³ç­–ç»“æœ**: 
- **Go**: æ‰€æœ‰å…³é”®æ¡ä»¶æ»¡è¶³ï¼Œå¯æ‰¹å‡†å‘å¸ƒ
- **Conditional Go**: æ¬¡è¦é—®é¢˜åœ¨ç›‘æ§ä¸‹å‘å¸ƒ  
- **No-Go**: é˜»å¡é—®é¢˜å¿…é¡»ä¿®å¤åå†è¯„ä¼°

---

## é™„å½•C: è¿ç»´æ‰‹å†Œä¸åº”æ€¥é¢„æ¡ˆ

### C.1 æ—¥å¸¸è¿ç»´SOP

#### ç³»ç»Ÿå¥åº·æ£€æŸ¥SOP
```bash
#!/bin/bash
# æ˜Ÿæ²³è¶…è„‘V2.3æ—¥å¸¸å¥åº·æ£€æŸ¥è„šæœ¬

echo "=== æ˜Ÿæ²³è¶…è„‘V2.3å¥åº·æ£€æŸ¥å¼€å§‹ ==="

# 1. æ ¸å¿ƒæœåŠ¡çŠ¶æ€æ£€æŸ¥
echo "æ£€æŸ¥æ ¸å¿ƒæœåŠ¡çŠ¶æ€..."
services=("brain-core" "memory-engine" "emotion-simulator" "multi-agent-coordinator")
for service in "${services[@]}"; do
    if systemctl is-active --quiet $service; then
        echo "âœ… $service æœåŠ¡æ­£å¸¸è¿è¡Œ"
    else
        echo "âŒ $service æœåŠ¡å¼‚å¸¸ï¼Œéœ€è¦ç«‹å³å…³æ³¨"
        exit 1
    fi
done

# 2. æ€§èƒ½æŒ‡æ ‡æ£€æŸ¥
echo "æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡..."
response_time=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8080/health)
if (( $(echo "$response_time < 0.2" | bc -l) )); then
    echo "âœ… å“åº”æ—¶é—´æ­£å¸¸: ${response_time}s"
else
    echo "âš ï¸ å“åº”æ—¶é—´å¼‚å¸¸: ${response_time}s"
fi

# 3. èµ„æºä½¿ç”¨æ£€æŸ¥
echo "æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ..."
memory_usage=$(free | grep Mem | awk '{printf "%.2f", $3/$2 * 100.0}')
cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')

if (( $(echo "$memory_usage < 80" | bc -l) )); then
    echo "âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸: ${memory_usage}%"
else
    echo "âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜: ${memory_usage}%"
fi

# 4. æ—¥å¿—é”™è¯¯æ£€æŸ¥
echo "æ£€æŸ¥æœ€è¿‘1å°æ—¶çš„é”™è¯¯æ—¥å¿—..."
error_count=$(journalctl -u brain-core --since "1 hour ago" | grep -c "ERROR")
if [ $error_count -lt 5 ]; then
    echo "âœ… é”™è¯¯æ—¥å¿—æ•°é‡æ­£å¸¸: $error_count æ¡"
else
    echo "âš ï¸ é”™è¯¯æ—¥å¿—è¿‡å¤š: $error_count æ¡ï¼Œéœ€è¦æ£€æŸ¥"
fi

echo "=== å¥åº·æ£€æŸ¥å®Œæˆ ==="
```

#### æ€§èƒ½è°ƒä¼˜SOP
```python
class PerformanceTuner:
    async def auto_tune_system(self):
        """è‡ªåŠ¨æ€§èƒ½è°ƒä¼˜æµç¨‹"""
        
        print("ğŸ”§ å¼€å§‹è‡ªåŠ¨æ€§èƒ½è°ƒä¼˜...")
        
        # 1. åˆ†æå½“å‰æ€§èƒ½ç“¶é¢ˆ
        bottlenecks = await self.analyze_bottlenecks()
        print(f"å‘ç°æ€§èƒ½ç“¶é¢ˆ: {bottlenecks}")
        
        # 2. åŠ¨æ€è°ƒæ•´å‚æ•°
        optimizations = []
        
        if "memory" in bottlenecks:
            await self.optimize_memory_usage()
            optimizations.append("å†…å­˜ä¼˜åŒ–")
            
        if "cpu" in bottlenecks:
            await self.optimize_cpu_usage()
            optimizations.append("CPUä¼˜åŒ–")
            
        if "io" in bottlenecks:
            await self.optimize_io_performance()
            optimizations.append("I/Oä¼˜åŒ–")
            
        # 3. éªŒè¯ä¼˜åŒ–æ•ˆæœ
        await asyncio.sleep(300)  # ç­‰å¾…5åˆ†é’Ÿè§‚å¯Ÿæ•ˆæœ
        after_metrics = await self.collect_performance_metrics()
        
        improvement = self.calculate_improvement(after_metrics)
        
        print(f"âœ… æ€§èƒ½è°ƒä¼˜å®Œæˆ:")
        print(f"   åº”ç”¨ä¼˜åŒ–: {', '.join(optimizations)}")
        print(f"   æ€§èƒ½æå‡: {improvement:.1%}")
        
        return {
            "optimizations": optimizations,
            "improvement": improvement,
            "timestamp": datetime.utcnow()
        }
```

### C.2 åº”æ€¥å“åº”é¢„æ¡ˆ

#### P0çº§æ•…éšœåº”æ€¥é¢„æ¡ˆ
```yaml
emergency_response_p0:
  trigger_conditions:
    - "ç³»ç»Ÿå®Œå…¨ä¸å¯ç”¨"
    - "æ•°æ®ä¸¢å¤±é£é™©"
    - "å®‰å…¨æ¼æ´è¢«åˆ©ç”¨"
    
  immediate_actions:
    - action: "æ¿€æ´»åº”æ€¥å“åº”å°ç»„"
      owner: "å€¼ç­å·¥ç¨‹å¸ˆ"
      timeout: "5åˆ†é’Ÿ"
      
    - action: "æ‰§è¡Œè‡ªåŠ¨æ•…éšœéš”ç¦»"
      owner: "ç›‘æ§ç³»ç»Ÿ"
      timeout: "2åˆ†é’Ÿ"
      
    - action: "å¯åŠ¨å¤‡ç”¨ç³»ç»Ÿ"
      owner: "åŸºç¡€è®¾æ–½å›¢é˜Ÿ"
      timeout: "10åˆ†é’Ÿ"
      
  communication_plan:
    internal:
      - "æŠ€æœ¯å›¢é˜Ÿç¾¤ç»„ (ç«‹å³)"
      - "ç®¡ç†å±‚é€šæŠ¥ (15åˆ†é’Ÿå†…)"
      - "å®¢æˆ·æœåŠ¡å›¢é˜Ÿ (30åˆ†é’Ÿå†…)"
      
    external:
      - "çŠ¶æ€é¡µæ›´æ–° (10åˆ†é’Ÿå†…)"
      - "å…³é”®å®¢æˆ·é€šçŸ¥ (30åˆ†é’Ÿå†…)"
      - "å…¬å¼€å£°æ˜ (å¦‚éœ€è¦ï¼Œ1å°æ—¶å†…)"
      
  recovery_steps:
    1. "é—®é¢˜å®šä½ä¸æ ¹å› åˆ†æ"
    2. "åˆ¶å®šä¿®å¤æ–¹æ¡ˆ"
    3. "åœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯ä¿®å¤"
    4. "ç”Ÿäº§ç¯å¢ƒæ¸è¿›å¼ä¿®å¤"
    5. "æœåŠ¡æ¢å¤éªŒè¯"
    6. "äº‹åæ€»ç»“ä¸æ”¹è¿›"
```

#### è‡ªåŠ¨å›æ»šæœºåˆ¶
```python
class AutoRollback:
    async def monitor_and_rollback(self, deployment_id: str):
        """è‡ªåŠ¨å›æ»šç›‘æ§æœºåˆ¶"""
        
        print(f"ğŸ” å¼€å§‹ç›‘æ§éƒ¨ç½² {deployment_id}")
        
        # ç›‘æ§å…³é”®æŒ‡æ ‡
        monitoring_duration = 1800  # 30åˆ†é’Ÿ
        check_interval = 60  # æ¯åˆ†é’Ÿæ£€æŸ¥
        
        start_time = time.time()
        rollback_triggered = False
        
        while time.time() - start_time < monitoring_duration:
            try:
                # æ£€æŸ¥å¥åº·æŒ‡æ ‡
                health_score = await self.calculate_health_score()
                
                # å›æ»šè§¦å‘æ¡ä»¶
                if health_score < 0.7:  # å¥åº·åˆ†æ•°ä½äº70%
                    print(f"âš ï¸ å¥åº·åˆ†æ•°è¿‡ä½: {health_score:.2%}")
                    await self.trigger_rollback(deployment_id)
                    rollback_triggered = True
                    break
                    
                # æ£€æŸ¥é”™è¯¯ç‡
                error_rate = await self.get_error_rate()
                if error_rate > 0.05:  # é”™è¯¯ç‡è¶…è¿‡5%
                    print(f"âš ï¸ é”™è¯¯ç‡è¿‡é«˜: {error_rate:.2%}")
                    await self.trigger_rollback(deployment_id)
                    rollback_triggered = True
                    break
                    
                print(f"âœ… å¥åº·æ£€æŸ¥é€šè¿‡ - åˆ†æ•°: {health_score:.2%}, é”™è¯¯ç‡: {error_rate:.2%}")
                await asyncio.sleep(check_interval)
                
            except Exception as e:
                print(f"âŒ ç›‘æ§å¼‚å¸¸: {e}")
                # ç›‘æ§å¼‚å¸¸ä¹Ÿè§¦å‘å›æ»š
                await self.trigger_rollback(deployment_id)
                rollback_triggered = True
                break
        
        if not rollback_triggered:
            print("âœ… éƒ¨ç½²ç›‘æ§æœŸç»“æŸï¼Œç³»ç»Ÿè¿è¡Œç¨³å®š")
            await self.mark_deployment_stable(deployment_id)
        
    async def trigger_rollback(self, deployment_id: str):
        """æ‰§è¡Œè‡ªåŠ¨å›æ»š"""
        print(f"ğŸ”„ è§¦å‘è‡ªåŠ¨å›æ»š: {deployment_id}")
        
        # 1. åœæ­¢å½“å‰éƒ¨ç½²æµé‡
        await self.stop_traffic_to_new_version()
        
        # 2. æ¢å¤åˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬
        previous_version = await self.get_previous_stable_version()
        await self.restore_version(previous_version)
        
        # 3. éªŒè¯å›æ»šæˆåŠŸ
        rollback_success = await self.verify_rollback_success()
        
        if rollback_success:
            print("âœ… è‡ªåŠ¨å›æ»šæˆåŠŸ")
            # å‘é€å›æ»šæˆåŠŸé€šçŸ¥
            await self.send_rollback_notification(deployment_id, "SUCCESS")
        else:
            print("âŒ è‡ªåŠ¨å›æ»šå¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥")
            await self.escalate_to_human(deployment_id)
```

---

## é™„å½•D: æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿ä¸æ•°æ®é›†

### D.1 æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿

#### åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿
```python
class TestCaseTemplate:
    """æ ‡å‡†åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹æ¨¡æ¿"""
    
    def setup_method(self):
        """æµ‹è¯•å‰ç½®æ¡ä»¶è®¾ç½®"""
        self.test_data = self.load_test_data()
        self.mock_dependencies = self.setup_mocks()
        self.system_under_test = self.initialize_system()
    
    def teardown_method(self):
        """æµ‹è¯•åæ¸…ç†"""
        self.cleanup_test_data()
        self.reset_system_state()
    
    @pytest.mark.parametrize("input_data,expected_output", [
        # æµ‹è¯•æ•°æ®å‚æ•°åŒ–
        ("æ­£å¸¸è¾“å…¥", "é¢„æœŸè¾“å‡º"),
        ("è¾¹ç•Œè¾“å…¥", "è¾¹ç•Œè¾“å‡º"),
        ("å¼‚å¸¸è¾“å…¥", "é”™è¯¯å¤„ç†")
    ])
    async def test_core_functionality(self, input_data, expected_output):
        """æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•æ¨¡æ¿
        
        æµ‹è¯•ç›®æ ‡: éªŒè¯æ ¸å¿ƒåŠŸèƒ½çš„æ­£ç¡®æ€§
        æµ‹è¯•çº§åˆ«: å•å…ƒæµ‹è¯•
        ä¼˜å…ˆçº§: P0
        """
        # Given - å‡†å¤‡æµ‹è¯•æ•°æ®
        test_context = TestContext(
            input=input_data,
            environment="test",
            user_context=self.default_user_context
        )
        
        # When - æ‰§è¡Œè¢«æµ‹è¯•åŠŸèƒ½
        result = await self.system_under_test.process(test_context)
        
        # Then - éªŒè¯ç»“æœ
        assert result.success is True
        assert result.output == expected_output
        assert result.execution_time < 0.1  # 100mså†…å®Œæˆ
        
        # éªŒè¯å‰¯ä½œç”¨
        assert self.verify_side_effects() is True
        
    async def test_error_handling(self):
        """é”™è¯¯å¤„ç†æµ‹è¯•æ¨¡æ¿"""
        with pytest.raises(ExpectedExceptionType) as exc_info:
            await self.system_under_test.process(invalid_input)
        
        assert "é¢„æœŸé”™è¯¯ä¿¡æ¯" in str(exc_info.value)
        assert exc_info.value.error_code == "EXPECTED_ERROR_CODE"
```

### D.2 æ€§èƒ½æµ‹è¯•æ•°æ®é›†

```yaml
performance_test_datasets:
  load_testing:
    small_scale:
      concurrent_users: 100
      duration_minutes: 10
      requests_per_user: 50
      
    medium_scale:
      concurrent_users: 500
      duration_minutes: 30
      requests_per_user: 100
      
    large_scale:
      concurrent_users: 1000
      duration_minutes: 60
      requests_per_user: 200
      
  stress_testing:
    cpu_intensive:
      operation_type: "complex_reasoning"
      iterations: 10000
      parallel_threads: 8
      
    memory_intensive:
      data_size_mb: 1024
      operations: ["create", "read", "update", "delete"]
      cycles: 1000
      
    io_intensive:
      file_operations: 50000
      database_queries: 100000
      network_requests: 25000

  endurance_testing:
    duration_hours: 72
    steady_load_qps: 100
    memory_leak_threshold: 0.1
    performance_degradation_threshold: 0.05
```

---

## é™„å½•E: å‚è€ƒèµ„æ–™ä¸æ ‡å‡†

### E.1 æŠ€æœ¯æ ‡å‡†å‚è€ƒ

- **è½¯ä»¶å·¥ç¨‹æ ‡å‡†**
  - ISO/IEC 25010:2011 - è½¯ä»¶è´¨é‡æ¨¡å‹
  - IEEE 829-2008 - è½¯ä»¶æµ‹è¯•æ–‡æ¡£æ ‡å‡†  
  - ISO/IEC 29119 - è½¯ä»¶æµ‹è¯•æ ‡å‡†ç³»åˆ—
  - CMMI-DEV v2.0 - èƒ½åŠ›æˆç†Ÿåº¦æ¨¡å‹

- **AIç³»ç»Ÿæ ‡å‡†**
  - ISO/IEC 23053 - AIç³»ç»Ÿæµ‹è¯•æ¡†æ¶
  - IEEE 2857-2021 - AIç³»ç»Ÿå·¥ç¨‹æ ‡å‡†
  - ISO/IEC 23894 - AIé£é™©ç®¡ç†æ ‡å‡†
  - IEEE 2857-2021 - æœºå™¨å­¦ä¹ æ¨¡å‹æ²»ç†

- **å®‰å…¨åˆè§„æ ‡å‡†**
  - ISO 27001:2013 - ä¿¡æ¯å®‰å…¨ç®¡ç†
  - GDPR - é€šç”¨æ•°æ®ä¿æŠ¤æ¡ä¾‹
  - CCPA - åŠ å·æ¶ˆè´¹è€…éšç§æ³•æ¡ˆ
  - SOX - è¨ç­æ–¯-å¥¥å…‹æ–¯åˆ©æ³•æ¡ˆ

### E.2 æœ€ä½³å®è·µå‚è€ƒ

- **DevOpså®è·µ**
  - The Phoenix Project (Gene Kimç­‰)
  - Accelerate (Nicole Forsgrenç­‰)  
  - Site Reliability Engineering (Google)
  - The DevOps Handbook (Gene Kimç­‰)

- **è½¯ä»¶è´¨é‡**
  - Clean Code (Robert Martin)
  - Refactoring (Martin Fowler)
  - Design Patterns (Gang of Four)
  - Domain-Driven Design (Eric Evans)

- **AIç³»ç»Ÿè®¾è®¡**
  - Designing Machine Learning Systems (Chip Huyen)
  - Machine Learning Engineering (Andriy Burkov)
  - AI Ethics (Joanna Bryson)
  - Human-Compatible AI (Stuart Russell)

### E.3 å¼€æºå·¥å…·ä¸æ¡†æ¶

```yaml
recommended_tools:
  testing_frameworks:
    unit_testing: ["pytest", "unittest", "nose2"]
    integration_testing: ["testcontainers", "docker-compose"]
    performance_testing: ["locust", "jmeter", "k6"]
    security_testing: ["bandit", "safety", "semgrep"]
    
  monitoring_tools:
    metrics: ["prometheus", "grafana", "datadog"]
    logging: ["elasticsearch", "logstash", "kibana"]
    tracing: ["jaeger", "zipkin", "opentelemetry"]
    
  deployment_tools:
    containerization: ["docker", "podman"]
    orchestration: ["kubernetes", "docker-swarm"]
    cicd: ["github-actions", "gitlab-ci", "jenkins"]
    
  quality_tools:
    code_analysis: ["sonarqube", "codeclimate", "deepsource"]
    dependency_scanning: ["snyk", "dependabot", "renovate"]
    documentation: ["sphinx", "mkdocs", "gitbook"]
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: V2.3.0  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ17æ—¥  
**æ–‡æ¡£çŠ¶æ€**: æ­£å¼ç‰ˆ  
**ç»´æŠ¤è´£ä»»**: æ˜Ÿæ²³è¶…è„‘æŠ€æœ¯å›¢é˜Ÿ

---

## ğŸ“Š ç›‘æ§ä¸é¢„è­¦æŒ‡æ ‡ä½“ç³»

### ç³»ç»Ÿå¥åº·åº¦ç›‘æ§

#### æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ (KPIs)

**1. å“åº”æ€§èƒ½æŒ‡æ ‡**
```yaml
performance_metrics:
  response_time:
    target: <200ms
    warning: 200-500ms
    critical: >500ms
    measurement_interval: 1s
  
  throughput:
    target: >10000 requests/min
    warning: 5000-10000 requests/min
    critical: <5000 requests/min
    measurement_interval: 1min
  
  availability:
    target: >99.9%
    warning: 99.5-99.9%
    critical: <99.5%
    measurement_window: 24h
```

**2. AIå¼•æ“æ€§èƒ½ç›‘æ§**
```python
class AIEngineMonitoring:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.performance_analyzer = PerformanceAnalyzer()
        self.alert_manager = AlertManager()
    
    async def monitor_ai_performance(self):
        """AIå¼•æ“æ€§èƒ½ç›‘æ§"""
        metrics = await self.collect_ai_metrics()
        
        # æ¨ç†å»¶è¿Ÿç›‘æ§
        if metrics.inference_latency > 2.0:  # ç§’
            await self.alert_manager.send_alert(
                type="performance_degradation",
                metric="inference_latency",
                value=metrics.inference_latency,
                threshold=2.0
            )
        
        # æ¨¡å‹å‡†ç¡®åº¦ç›‘æ§
        if metrics.model_accuracy < 0.95:
            await self.alert_manager.send_alert(
                type="accuracy_drop",
                metric="model_accuracy",
                value=metrics.model_accuracy,
                threshold=0.95
            )
        
        # å†…å­˜ä½¿ç”¨ç›‘æ§
        if metrics.memory_usage > 0.85:  # 85%
            await self.alert_manager.send_alert(
                type="resource_exhaustion",
                metric="memory_usage",
                value=metrics.memory_usage,
                threshold=0.85
            )
    
    async def collect_ai_metrics(self) -> AIMetrics:
        """æ”¶é›†AIå¼•æ“æŒ‡æ ‡"""
        return AIMetrics(
            inference_latency=await self.measure_inference_time(),
            model_accuracy=await self.calculate_accuracy(),
            memory_usage=await self.get_memory_usage(),
            gpu_utilization=await self.get_gpu_usage(),
            request_queue_size=await self.get_queue_size()
        )
```

**3. ä¼¦ç†åˆè§„ç›‘æ§**
```python
class EthicsComplianceMonitor:
    def __init__(self):
        self.ethics_analyzer = EthicsAnalyzer()
        self.compliance_checker = ComplianceChecker()
        self.violation_tracker = ViolationTracker()
    
    async def monitor_ethics_compliance(self):
        """ä¼¦ç†åˆè§„ç›‘æ§"""
        # å†³ç­–é€æ˜åº¦æ£€æŸ¥
        transparency_score = await self.ethics_analyzer.measure_transparency()
        if transparency_score < 0.8:
            await self.log_ethics_concern(
                type="transparency_low",
                score=transparency_score,
                threshold=0.8
            )
        
        # åè§æ£€æµ‹
        bias_indicators = await self.ethics_analyzer.detect_bias()
        if any(indicator.severity == "high" for indicator in bias_indicators):
            await self.trigger_bias_investigation(bias_indicators)
        
        # éšç§ä¿æŠ¤æ£€æŸ¥
        privacy_violations = await self.compliance_checker.check_privacy()
        if privacy_violations:
            await self.handle_privacy_violations(privacy_violations)
    
    async def trigger_bias_investigation(self, indicators: List[BiasIndicator]):
        """è§¦å‘åè§è°ƒæŸ¥"""
        investigation = BiasInvestigation(
            indicators=indicators,
            triggered_at=datetime.now(),
            status="active"
        )
        
        # æš‚åœç›¸å…³æ¨¡å‹æ¨ç†
        for indicator in indicators:
            if indicator.severity == "critical":
                await self.suspend_model(indicator.model_id)
        
        # é€šçŸ¥ç ”å‘å›¢é˜Ÿ
        await self.alert_manager.send_alert(
            type="bias_detection",
            urgency="high",
            investigation_id=investigation.id
        )
```

#### ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§

**4. ç”¨æˆ·ä½“éªŒæŒ‡æ ‡**
```python
class UserExperienceMonitor:
    async def track_user_satisfaction(self):
        """ç”¨æˆ·æ»¡æ„åº¦è·Ÿè¸ª"""
        satisfaction_metrics = await self.collect_satisfaction_data()
        
        # ç”¨æˆ·æ»¡æ„åº¦è¶‹åŠ¿åˆ†æ
        trend = self.analyze_satisfaction_trend(satisfaction_metrics)
        if trend.direction == "declining" and trend.rate > 0.1:
            await self.alert_manager.send_alert(
                type="user_satisfaction_decline",
                trend=trend,
                current_score=satisfaction_metrics.average_score
            )
        
        # åŠŸèƒ½ä½¿ç”¨ç‡åˆ†æ
        feature_usage = await self.analyze_feature_usage()
        underused_features = [
            feature for feature in feature_usage 
            if feature.usage_rate < 0.1  # ä½¿ç”¨ç‡ä½äº10%
        ]
        
        if underused_features:
            await self.schedule_feature_review(underused_features)
    
    async def monitor_user_engagement(self):
        """ç”¨æˆ·å‚ä¸åº¦ç›‘æ§"""
        engagement_metrics = {
            "daily_active_users": await self.get_dau(),
            "session_duration": await self.get_avg_session_duration(),
            "feature_adoption_rate": await self.get_feature_adoption(),
            "user_retention_rate": await self.get_retention_rate()
        }
        
        # å‚ä¸åº¦å¼‚å¸¸æ£€æµ‹
        for metric_name, value in engagement_metrics.items():
            threshold = self.get_threshold(metric_name)
            if value < threshold:
                await self.alert_manager.send_alert(
                    type="engagement_drop",
                    metric=metric_name,
                    value=value,
                    threshold=threshold
                )
```

**5. ç³»ç»Ÿç¨³å®šæ€§ç›‘æ§**
```python
class SystemStabilityMonitor:
    def __init__(self):
        self.stability_analyzer = StabilityAnalyzer()
        self.anomaly_detector = AnomalyDetector()
        self.health_checker = HealthChecker()
    
    async def monitor_system_stability(self):
        """ç³»ç»Ÿç¨³å®šæ€§ç›‘æ§"""
        stability_report = await self.stability_analyzer.generate_report()
        
        # é”™è¯¯ç‡è¶‹åŠ¿åˆ†æ
        if stability_report.error_rate > 0.01:  # 1%
            await self.investigate_error_spike(stability_report)
        
        # ç³»ç»Ÿèµ„æºä½¿ç”¨åˆ†æ
        resource_usage = await self.get_resource_usage()
        if any(usage > 0.9 for usage in resource_usage.values()):
            await self.trigger_resource_scaling(resource_usage)
        
        # ä¾èµ–æœåŠ¡å¥åº·æ£€æŸ¥
        dependency_health = await self.check_dependencies()
        unhealthy_deps = [
            dep for dep in dependency_health 
            if dep.status != "healthy"
        ]
        
        if unhealthy_deps:
            await self.handle_dependency_issues(unhealthy_deps)
    
    async def predict_system_failures(self):
        """ç³»ç»Ÿæ•…éšœé¢„æµ‹"""
        # æ”¶é›†å†å²æ•°æ®
        historical_data = await self.get_historical_metrics()
        
        # AIé¢„æµ‹æ¨¡å‹åˆ†æ
        failure_prediction = await self.anomaly_detector.predict_failures(
            historical_data
        )
        
        # é¢„è­¦è§¦å‘
        if failure_prediction.probability > 0.7:
            await self.trigger_proactive_maintenance(failure_prediction)
```

### é¢„è­¦è§„åˆ™å¼•æ“

```python
class AlertRuleEngine:
    def __init__(self):
        self.rule_processor = RuleProcessor()
        self.alert_dispatcher = AlertDispatcher()
        self.escalation_manager = EscalationManager()
    
    async def process_alert_rules(self, metrics: SystemMetrics):
        """å¤„ç†å‘Šè­¦è§„åˆ™"""
        triggered_alerts = []
        
        # åº”ç”¨æ‰€æœ‰å‘Šè­¦è§„åˆ™
        for rule in self.get_active_rules():
            if await rule.evaluate(metrics):
                alert = Alert(
                    rule_id=rule.id,
                    severity=rule.severity,
                    message=rule.generate_message(metrics),
                    timestamp=datetime.now()
                )
                triggered_alerts.append(alert)
        
        # å‘Šè­¦å»é‡å’Œèšåˆ
        deduplicated_alerts = self.deduplicate_alerts(triggered_alerts)
        
        # å‘é€å‘Šè­¦
        for alert in deduplicated_alerts:
            await self.alert_dispatcher.send_alert(alert)
            
            # å‡çº§å¤„ç†
            if alert.severity == "critical":
                await self.escalation_manager.start_escalation(alert)
    
    def get_active_rules(self) -> List[AlertRule]:
        """è·å–æ¿€æ´»çš„å‘Šè­¦è§„åˆ™"""
        return [
            # ç³»ç»Ÿæ€§èƒ½è§„åˆ™
            AlertRule(
                id="high_cpu_usage",
                condition="cpu_usage > 0.8",
                severity="warning",
                duration="5m"
            ),
            AlertRule(
                id="critical_cpu_usage", 
                condition="cpu_usage > 0.95",
                severity="critical",
                duration="1m"
            ),
            
            # AIå¼•æ“è§„åˆ™
            AlertRule(
                id="model_accuracy_drop",
                condition="model_accuracy < 0.9",
                severity="warning",
                duration="10m"
            ),
            
            # ä¸šåŠ¡æŒ‡æ ‡è§„åˆ™
            AlertRule(
                id="user_satisfaction_low",
                condition="user_satisfaction < 4.0",
                severity="warning",
                duration="1h"
            ),
            
            # å®‰å…¨è§„åˆ™
            AlertRule(
                id="unusual_access_pattern",
                condition="failed_login_rate > 0.1",
                severity="critical",
                duration="5m"
            )
        ]
```

---

## ğŸ§ª å…¨é¢æµ‹è¯•é¡¹è®¾è®¡

### æµ‹è¯•ç­–ç•¥æ¡†æ¶

#### æµ‹è¯•é‡‘å­—å¡”æ¨¡å‹

```
        E2E Tests (10%)
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  ç”¨æˆ·éªŒæ”¶æµ‹è¯•    â”‚
     â”‚  ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
      Integration Tests (20%)
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    APIé›†æˆæµ‹è¯•       â”‚
   â”‚   æœåŠ¡é—´é›†æˆæµ‹è¯•      â”‚
  â”‚    æ•°æ®åº“é›†æˆæµ‹è¯•      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        Unit Tests (70%)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚      å•å…ƒæµ‹è¯•            â”‚
 â”‚    ç»„ä»¶æµ‹è¯•              â”‚
â”‚     å‡½æ•°æµ‹è¯•              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. åŠŸèƒ½æµ‹è¯•å¥—ä»¶

#### 1.1 AIå¼•æ“åŠŸèƒ½æµ‹è¯•

**æ–‡æœ¬å¤„ç†æµ‹è¯•**:
```python
class TextProcessingTests:
    async def test_multilingual_understanding(self):
        """å¤šè¯­è¨€ç†è§£æµ‹è¯•"""
        test_cases = [
            {"text": "Hello, how are you?", "language": "en", "expected_intent": "greeting"},
            {"text": "ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ", "language": "zh", "expected_intent": "greeting"},
            {"text": "Bonjour, comment allez-vous?", "language": "fr", "expected_intent": "greeting"},
            {"text": "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ", "language": "ja", "expected_intent": "greeting"}
        ]
        
        for case in test_cases:
            result = await self.ai_engine.process_text(case["text"])
            assert result.language == case["language"]
            assert result.intent == case["expected_intent"]
            assert result.confidence > 0.9
    
    async def test_context_understanding(self):
        """ä¸Šä¸‹æ–‡ç†è§£æµ‹è¯•"""
        conversation = [
            "æˆ‘æƒ³é¢„è®¢ä¸€å¼ æœºç¥¨",
            "ä»åŒ—äº¬åˆ°ä¸Šæµ·",
            "æ˜å¤©ä¸‹åˆçš„èˆªç­",
            "ç»æµèˆ±å°±å¯ä»¥"
        ]
        
        context = {}
        for message in conversation:
            result = await self.ai_engine.process_text(message, context)
            context.update(result.context)
        
        # éªŒè¯æœ€ç»ˆä¸Šä¸‹æ–‡åŒ…å«å®Œæ•´ä¿¡æ¯
        assert context["intent"] == "book_flight"
        assert context["departure"] == "åŒ—äº¬"
        assert context["destination"] == "ä¸Šæµ·"
        assert context["date"] == "æ˜å¤©"
        assert context["time"] == "ä¸‹åˆ"
        assert context["class"] == "ç»æµèˆ±"
    
    async def test_emotion_recognition(self):
        """æƒ…æ„Ÿè¯†åˆ«æµ‹è¯•"""
        emotion_tests = [
            {"text": "æˆ‘ä»Šå¤©éå¸¸å¼€å¿ƒï¼", "expected_emotion": "joy", "intensity": "high"},
            {"text": "è¿™è®©æˆ‘å¾ˆç”Ÿæ°”", "expected_emotion": "anger", "intensity": "medium"},
            {"text": "æˆ‘æ„Ÿåˆ°æœ‰ç‚¹æ‹…å¿ƒ", "expected_emotion": "anxiety", "intensity": "low"},
            {"text": "å¤ªä»¤äººæƒŠè®¶äº†ï¼", "expected_emotion": "surprise", "intensity": "high"}
        ]
        
        for test in emotion_tests:
            result = await self.ai_engine.analyze_emotion(test["text"])
            assert result.primary_emotion == test["expected_emotion"]
            assert result.intensity == test["intensity"]
            assert result.confidence > 0.8
```

**å›¾åƒå¤„ç†æµ‹è¯•**:
```python
class ImageProcessingTests:
    async def test_object_detection(self):
        """ç‰©ä½“æ£€æµ‹æµ‹è¯•"""
        test_images = [
            {"path": "test_images/cat_dog.jpg", "expected_objects": ["cat", "dog"]},
            {"path": "test_images/traffic_scene.jpg", "expected_objects": ["car", "traffic_light", "person"]},
            {"path": "test_images/office.jpg", "expected_objects": ["computer", "desk", "chair"]}
        ]
        
        for test_image in test_images:
            image_data = await self.load_image(test_image["path"])
            result = await self.ai_engine.detect_objects(image_data)
            
            detected_objects = [obj.label for obj in result.objects]
            for expected_obj in test_image["expected_objects"]:
                assert expected_obj in detected_objects
                
            # éªŒè¯æ£€æµ‹ç²¾åº¦
            for obj in result.objects:
                assert obj.confidence > 0.8
    
    async def test_scene_understanding(self):
        """åœºæ™¯ç†è§£æµ‹è¯•"""
        scene_tests = [
            {"image": "beach_sunset.jpg", "expected_scene": "beach", "expected_time": "sunset"},
            {"image": "office_meeting.jpg", "expected_scene": "office", "expected_activity": "meeting"},
            {"image": "kitchen_cooking.jpg", "expected_scene": "kitchen", "expected_activity": "cooking"}
        ]
        
        for test in scene_tests:
            image_data = await self.load_image(test["image"])
            result = await self.ai_engine.understand_scene(image_data)
            
            assert result.scene_type == test["expected_scene"]
            if "expected_time" in test:
                assert result.time_of_day == test["expected_time"]
            if "expected_activity" in test:
                assert result.main_activity == test["expected_activity"]
    
    async def test_image_generation(self):
        """å›¾åƒç”Ÿæˆæµ‹è¯•"""
        generation_prompts = [
            {"prompt": "ä¸€åªå¯çˆ±çš„å°çŒ«åœ¨èŠ±å›­é‡Œç©è€", "style": "realistic"},
            {"prompt": "æœªæ¥åŸå¸‚çš„ç§‘å¹»æ™¯è§‚", "style": "sci-fi"},
            {"prompt": "æŠ½è±¡è‰ºæœ¯é£æ ¼çš„å±±æ°´ç”»", "style": "abstract"}
        ]
        
        for prompt_test in generation_prompts:
            result = await self.ai_engine.generate_image(
                prompt_test["prompt"], 
                style=prompt_test["style"]
            )
            
            # éªŒè¯å›¾åƒè´¨é‡
            assert result.image_quality > 0.9
            assert result.prompt_adherence > 0.85
            assert result.style_consistency > 0.8
            
            # éªŒè¯å›¾åƒå±æ€§
            assert result.resolution >= (1024, 1024)
            assert result.format in ["PNG", "JPEG"]
```

**è¯­éŸ³å¤„ç†æµ‹è¯•**:
```python
class VoiceProcessingTests:
    async def test_speech_recognition(self):
        """è¯­éŸ³è¯†åˆ«æµ‹è¯•"""
        audio_tests = [
            {"file": "clear_speech.wav", "expected_text": "ä»Šå¤©å¤©æ°”å¾ˆå¥½", "noise_level": "low"},
            {"file": "noisy_speech.wav", "expected_text": "è¯·å¸®æˆ‘é¢„è®¢é¤å…", "noise_level": "high"},
            {"file": "accented_speech.wav", "expected_text": "æˆ‘æ¥è‡ªå¹¿ä¸œ", "accent": "cantonese"}
        ]
        
        for test in audio_tests:
            audio_data = await self.load_audio(test["file"])
            result = await self.ai_engine.recognize_speech(audio_data)
            
            # è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
            similarity = self.calculate_text_similarity(
                result.text, test["expected_text"]
            )
            assert similarity > 0.9
            
            # éªŒè¯ç½®ä¿¡åº¦
            assert result.confidence > 0.85
    
    async def test_voice_synthesis(self):
        """è¯­éŸ³åˆæˆæµ‹è¯•"""
        synthesis_tests = [
            {"text": "æ¬¢è¿ä½¿ç”¨æ˜Ÿæ²³è¶…è„‘", "voice": "female", "emotion": "friendly"},
            {"text": "ç³»ç»Ÿæ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚", "voice": "male", "emotion": "professional"},
            {"text": "å¾ˆæŠ±æ­‰ï¼Œå‡ºç°äº†é”™è¯¯", "voice": "female", "emotion": "apologetic"}
        ]
        
        for test in synthesis_tests:
            result = await self.ai_engine.synthesize_voice(
                text=test["text"],
                voice_type=test["voice"],
                emotion=test["emotion"]
            )
            
            # éªŒè¯éŸ³é¢‘è´¨é‡
            assert result.audio_quality > 0.9
            assert result.naturalness > 0.85
```

#### 1.2 è®¤çŸ¥ä¸ä¼¦ç†æµ‹è¯•

```python
class EthicsAndCognitionTests:
    async def test_decision_requires_evidence_and_rollback(self):
        """éªŒè¯ä¼¦ç†é—¨ç¦ï¼šè¯æ®é˜ˆå€¼ã€å¯å›æ»šã€éšç§é£é™©"""
        plan = await self.ai_engine.propose_plan(
            goal="publish_health_advice",
            context={"truth_evidence": 0.8,
                     "rollback_available": True,
                     "privacy_risk": "low"}
        )
        allowed = await self.ai_engine.ethics.permit(plan)
        assert allowed is True
    
    async def test_block_when_low_evidence(self):
        plan = await self.ai_engine.propose_plan(
            goal="publish_health_advice",
            context={"truth_evidence": 0.5,
                     "rollback_available": True,
                     "privacy_risk": "low"}
        )
        allowed = await self.ai_engine.ethics.permit(plan)
        assert allowed is False
```

#### 1.3 è®°å¿†ä¸æ³›åŒ–æµ‹è¯•

```python
class MemoryGeneralizationTests:
    async def test_recall_topk(self):
        """å‘é‡+ç¬¦å·å¤šç´¢å¼•æ£€ç´¢å‡†ç¡®ç‡"""
        await self.memory.upsert_item(
            text="ç”¨æˆ·åå¥½: å–œæ¬¢ç§‘å¹»ç”µå½±",
            tags=["preference", "movie"],
        )
        results = await self.memory.retrieve(
            query="æ¨èä¸€éƒ¨ç§‘å¹»ç‰‡", k=5
        )
        texts = [r.text for r in results]
        assert any("ç§‘å¹»" in t for t in texts)
    
    async def test_abstraction_stability(self):
        """æ¦‚å¿µå½’çº³åœ¨å™ªå£°ä¸‹ç¨³å®šæ€§(æŒ‡æ ‡Î”<=5%)"""
        base = await self.generalizer.score_on(
            dataset="clean_preference"
        )
        noisy = await self.generalizer.score_on(
            dataset="noisy_preference"
        )
        assert abs(base - noisy) <= 0.05
```

#### 1.4 å¤šæ™ºèƒ½ä½“åä½œæµ‹è¯•

```python
class MultiAgentCollabTests:
    async def test_pipeline_completion(self):
        """Planner->Researcher->Coder->Tester é—­ç¯å®Œæˆç‡"""
        result = await self.collab.run_pipeline(
            goal="å®ç°å¹¶æµ‹è¯•æ’åºç®—æ³•"
        )
        assert result.success is True
        assert result.metrics["latency_s"] < 60
    
    async def test_isolation_on_agent_failure(self):
        """å•Agentå¤±è´¥ä¸æ‰©æ•£ï¼Œè‡ªåŠ¨æ›¿è¡¥æˆ–é™çº§"""
        outcome = await self.collab.run_with_fault_injection(
            agent="Researcher", fault="timeout"
        )
        assert outcome.degraded is True
        assert outcome.root_cause == "Researcher_timeout"
```

#### 1.5 æƒ…æ„Ÿäº¤äº’æµ‹è¯•

```python
class AffectiveInteractionTests:
    async def test_state_update_with_appraisal(self):
        """æƒ…æ„ŸçŠ¶æ€éšè¯„ä¼°ç»´åº¦åˆç†æ³¢åŠ¨å¹¶æˆªæ–­"""
        st0 = await self.affect.get_state()
        await self.affect.update(
            appraisal={"relevance": 0.8,
                       "novelty": 0.6,
                       "control": 0.4}
        )
        st1 = await self.affect.get_state()
        assert -1.0 <= st1.valence <= 1.0
        assert st1.valence != st0.valence
    
    async def test_tts_emotion_mapping(self):
        """æƒ…æ„ŸTTSæ˜ å°„å‚æ•°åœ¨è¾¹ç•Œå†…ä¸”å¯æ§"""
        audio = await self.ai_engine.synthesize_voice(
            text="å¾ˆé«˜å…´è§åˆ°ä½ ", voice_type="female",
            emotion="joy"
        )
        assert audio.naturalness > 0.85
        assert 0.8 <= audio.pitch_factor <= 1.2
```

#### 1.6 éåŠŸèƒ½æµ‹è¯•å¥—ä»¶

**æ€§èƒ½æµ‹è¯•**:
```python
class PerformanceTests:
    async def test_response_time_slo(self):
        """å“åº”æ—¶é—´SLOæµ‹è¯•: P95 < 200ms"""
        test_requests = 1000
        response_times = []
        
        async with AsyncLoad(concurrency=50) as loader:
            for _ in range(test_requests):
                start_time = time.time()
                await self.ai_engine.process_query("ç®€å•æŸ¥è¯¢æµ‹è¯•")
                response_times.append(time.time() - start_time)
        
        p95_response_time = np.percentile(response_times, 95)
        assert p95_response_time < 0.2  # 200ms
        
        # éªŒè¯å¹³å‡å“åº”æ—¶é—´
        avg_response_time = np.mean(response_times)
        assert avg_response_time < 0.1  # 100ms
    
    async def test_throughput_capacity(self):
        """ååé‡å®¹é‡æµ‹è¯•: >= 1000 QPS"""
        duration = 60  # 60ç§’å‹æµ‹
        start_time = time.time()
        completed_requests = 0
        
        async with AsyncLoad(concurrency=100) as loader:
            while time.time() - start_time < duration:
                await self.ai_engine.process_query("ååé‡æµ‹è¯•æŸ¥è¯¢")
                completed_requests += 1
        
        qps = completed_requests / duration
        assert qps >= 1000
    
    async def test_memory_usage_stability(self):
        """å†…å­˜ä½¿ç”¨ç¨³å®šæ€§æµ‹è¯•"""
        initial_memory = await self.monitor.get_memory_usage()
        
        # æ‰§è¡Œå¤§é‡æ“ä½œ
        for i in range(10000):
            await self.ai_engine.process_query(f"å†…å­˜æµ‹è¯•æŸ¥è¯¢ {i}")
            if i % 100 == 0:
                # è§¦å‘åƒåœ¾å›æ”¶
                import gc; gc.collect()
        
        final_memory = await self.monitor.get_memory_usage()
        memory_growth = final_memory - initial_memory
        
        # å†…å­˜å¢é•¿ä¸è¶…è¿‡åˆå§‹çš„20%
        assert memory_growth / initial_memory < 0.2
```

**å¯é æ€§æµ‹è¯•**:
```python
class ReliabilityTests:
    async def test_fault_tolerance(self):
        """æ•…éšœå®¹é”™æµ‹è¯•"""
        fault_scenarios = [
            {"type": "network_partition", "duration": 30},
            {"type": "database_timeout", "duration": 10},
            {"type": "memory_pressure", "intensity": 0.8},
            {"type": "cpu_spike", "intensity": 0.9}
        ]
        
        for scenario in fault_scenarios:
            async with FaultInjector(scenario) as injector:
                # åœ¨æ•…éšœæœŸé—´æŒç»­å‘é€è¯·æ±‚
                success_count = 0
                total_requests = 100
                
                for _ in range(total_requests):
                    try:
                        result = await self.ai_engine.process_query("æ•…éšœæµ‹è¯•")
                        if result.success:
                            success_count += 1
                    except Exception:
                        pass
                
                # å³ä½¿åœ¨æ•…éšœæƒ…å†µä¸‹ï¼ŒæˆåŠŸç‡åº”è¯¥ >= 95%
                success_rate = success_count / total_requests
                assert success_rate >= 0.95
    
    async def test_graceful_degradation(self):
        """ä¼˜é›…é™çº§æµ‹è¯•"""
        # æ¨¡æ‹Ÿé«˜çº§åŠŸèƒ½ä¸å¯ç”¨
        with mock.patch.object(self.ai_engine, 'advanced_reasoning', 
                              side_effect=Exception("æœåŠ¡ä¸å¯ç”¨")):
            
            result = await self.ai_engine.process_query("å¤æ‚æ¨ç†é—®é¢˜")
            
            # åº”è¯¥é™çº§åˆ°åŸºç¡€åŠŸèƒ½
            assert result.success is True
            assert result.degraded is True
            assert result.fallback_method == "basic_reasoning"
```

**å®‰å…¨æµ‹è¯•**:
```python
class SecurityTests:
    async def test_input_sanitization(self):
        """è¾“å…¥æ¸…ç†æµ‹è¯•"""
        malicious_inputs = [
            "<script>alert('XSS')</script>",
            "'; DROP TABLE users; --",
            "{{7*7}}",  # æ¨¡æ¿æ³¨å…¥
            "../../../etc/passwd",  # è·¯å¾„éå†
            "javascript:alert('XSS')"
        ]
        
        for malicious_input in malicious_inputs:
            result = await self.ai_engine.process_query(malicious_input)
            
            # éªŒè¯è¾“å‡ºå·²è¢«æ¸…ç†
            assert "<script>" not in result.response
            assert "DROP TABLE" not in result.response
            assert result.sanitized is True
    
    async def test_rate_limiting(self):
        """é€Ÿç‡é™åˆ¶æµ‹è¯•"""
        user_id = "test_user_123"
        requests_per_minute = 60
        
        # å¿«é€Ÿå‘é€è¶…è¿‡é™åˆ¶çš„è¯·æ±‚
        tasks = []
        for i in range(requests_per_minute + 10):
            task = self.ai_engine.process_query(
                f"é€Ÿç‡æµ‹è¯• {i}", user_id=user_id
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # éªŒè¯æœ‰è¯·æ±‚è¢«é™åˆ¶
        rate_limited_count = sum(
            1 for r in results 
            if isinstance(r, RateLimitException)
        )
        assert rate_limited_count >= 10
    
    async def test_data_privacy(self):
        """æ•°æ®éšç§æµ‹è¯•"""
        sensitive_data = {
            "phone": "13800138000",
            "email": "test@example.com",
            "id_card": "110101199001011234",
            "credit_card": "4111111111111111"
        }
        
        for data_type, value in sensitive_data.items():
            query = f"æˆ‘çš„{data_type}æ˜¯{value}"
            result = await self.ai_engine.process_query(query)
            
            # éªŒè¯æ•æ„Ÿæ•°æ®è¢«è„±æ•
            assert value not in result.response
            assert "*" in result.response or "***" in result.response
            
            # éªŒè¯æ—¥å¿—ä¸­ä¸åŒ…å«æ•æ„Ÿæ•°æ®
            logs = await self.log_service.get_recent_logs()
            for log in logs:
                assert value not in log.message
```

### 2. æµ‹è¯•æ•°æ®ä¸ç¯å¢ƒç®¡ç†

#### 2.1 æµ‹è¯•æ•°æ®ç®¡ç†ç­–ç•¥

```yaml
test_data_management:
  synthetic_data:
    generation_rules:
      - type: "conversation_data"
        volume: 10000
        languages: ["zh", "en", "ja", "fr"]
        domains: ["customer_service", "education", "entertainment", "business"]
      
      - type: "multimodal_data" 
        images: 5000
        audio_clips: 3000
        video_segments: 1000
        quality_levels: ["high", "medium", "low"]
    
    privacy_compliance:
      - no_real_personal_data: true
      - gdpr_compliant: true
      - data_retention_days: 30
      - automatic_cleanup: true

  test_environments:
    unit_test:
      isolation: "complete"
      data_scope: "minimal"
      reset_strategy: "per_test"
    
    integration_test:
      isolation: "service_level" 
      data_scope: "representative"
      reset_strategy: "per_suite"
    
    e2e_test:
      isolation: "environment_level"
      data_scope: "full_scenario"
      reset_strategy: "per_release"
```

#### 2.2 ç¯å¢ƒä¸€è‡´æ€§ä¿è¯

```python
class EnvironmentManager:
    async def ensure_test_environment(self, test_type: str):
        """ç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸€è‡´æ€§"""
        config = self.get_environment_config(test_type)
        
        # éªŒè¯ä¾èµ–æœåŠ¡çŠ¶æ€
        dependencies = await self.check_dependencies(config.dependencies)
        assert all(dep.healthy for dep in dependencies)
        
        # ç¡®ä¿æ•°æ®åº“schemaç‰ˆæœ¬ä¸€è‡´
        db_version = await self.get_database_version()
        assert db_version == config.expected_db_version
        
        # éªŒè¯é…ç½®ä¸€è‡´æ€§
        current_config = await self.get_runtime_config()
        assert current_config.hash == config.expected_config_hash
        
        return EnvironmentState(
            ready=True,
            version=config.version,
            validated_at=datetime.utcnow()
        )
```

### 3. æµ‹è¯•è‡ªåŠ¨åŒ–ä¸CI/CDé›†æˆ

#### 3.1 CI/CDæµæ°´çº¿é›†æˆ

```yaml
# .github/workflows/test-pipeline.yml
name: æ˜Ÿæ²³è¶…è„‘V2.3æµ‹è¯•æµæ°´çº¿

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: è¿è¡Œå•å…ƒæµ‹è¯•
        run: |
          pytest tests/unit/ -v --cov=src --cov-report=xml
          
      - name: ä¸Šä¼ è¦†ç›–ç‡æŠ¥å‘Š
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: true
          
  integration-tests:
    needs: unit-tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: è¿è¡Œé›†æˆæµ‹è¯•
        run: pytest tests/integration/ -v
        
  performance-tests:
    needs: integration-tests  
    runs-on: ubuntu-latest
    steps:
      - name: è¿è¡Œæ€§èƒ½æµ‹è¯•
        run: |
          pytest tests/performance/ -v
          python scripts/performance_report.py
          
  security-tests:
    needs: integration-tests
    runs-on: ubuntu-latest
    steps:
      - name: å®‰å…¨æ‰«æ
        run: |
          bandit -r src/
          safety check
          pytest tests/security/ -v
          
  e2e-tests:
    needs: [integration-tests, performance-tests, security-tests]
    runs-on: ubuntu-latest
    steps:
      - name: è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•
        run: pytest tests/e2e/ -v --browser=headless
        
  test-report:
    needs: [unit-tests, integration-tests, performance-tests, security-tests, e2e-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        run: |
          python scripts/generate_test_report.py
          python scripts/update_quality_dashboard.py
```

#### 3.2 è´¨é‡é—¨ç¦è‡ªåŠ¨åŒ–

```python
class QualityGateAutomation:
    async def evaluate_quality_gates(self, test_results: TestResults) -> GateResult:
        """è‡ªåŠ¨åŒ–è´¨é‡é—¨ç¦è¯„ä¼°"""
        gates = []
        
        # ä»£ç è¦†ç›–ç‡é—¨ç¦
        coverage_gate = await self.check_coverage_gate(test_results.coverage)
        gates.append(coverage_gate)
        
        # æ€§èƒ½é—¨ç¦  
        performance_gate = await self.check_performance_gate(test_results.performance)
        gates.append(performance_gate)
        
        # å®‰å…¨é—¨ç¦
        security_gate = await self.check_security_gate(test_results.security)  
        gates.append(security_gate)
        
        # åŠŸèƒ½æµ‹è¯•é—¨ç¦
        functional_gate = await self.check_functional_gate(test_results.functional)
        gates.append(functional_gate)
        
        overall_result = GateResult(
            passed=all(gate.passed for gate in gates),
            gates=gates,
            recommendation=self.get_recommendation(gates)
        )
        
        # è‡ªåŠ¨åŒ–å†³ç­–
        if overall_result.passed:
            await self.approve_for_deployment()
        else:
            await self.block_deployment(overall_result.failed_gates)
            
        return overall_result
    
    async def check_coverage_gate(self, coverage_data: CoverageData) -> Gate:
        """æ£€æŸ¥ä»£ç è¦†ç›–ç‡é—¨ç¦"""
        thresholds = {
            "line_coverage": 0.85,
            "branch_coverage": 0.80,
            "function_coverage": 0.90
        }
        
        passed = all(
            coverage_data.get(metric) >= threshold
            for metric, threshold in thresholds.items()
        )
        
        return Gate(
            name="ä»£ç è¦†ç›–ç‡",
            passed=passed,
            metrics=coverage_data,
            thresholds=thresholds
        )
```

---